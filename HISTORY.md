一年半以前，AlphaGo完胜李世乭的围棋赛让深度学习（Deep Learning）这个名词家喻户晓，再度掀起人工智能的新一波热潮。其实深度学习背后的神经网络基础理论早在上世纪50年代就已提出，经过几起几落的发展，到了21世纪初，多层神经网络算法也日趋成熟。深度学习理论早在十多年以前就有重要突破，为何直到近年才出现爆发。这不得不提到2012年的一场竞赛。

2012年，Geoffrey E. Hinton（与Yann LeCun 和Yoshua Bengio并称为深度学习三驾马车）的弟子Alex Krizhevsky在ILSVRC-2012的图像分类比赛中使用2块Nvidia GTX 580 GPU训练的多层神经网络（后来被称为AlexNet）以15.3%的top-5测试错误率摘得冠军，而使用传统方法的第二名的成绩是26.2%，整整提高了10多个百分点。这也成为了深度学习发展史上的里程碑事件，从此深度神经网络一炮走红，此后ILSVRC的优胜者一直被深度神经网络霸占。

可以说深度学习爆发有两个主要原因，一个是像ImageNet这样的大规模数据集的出现，而另一个重要原因就是计算能力的提高，而这主要得益于GPU用于深度学习的加速，尤其是深度学习训练的加速。

Alex当时使用的数据集包含120万张高清图片，受限于单块GTX 580 GPU 3GB的内存，他们使用了2块GPU来训练他们包含6000万参数和65万神经节点的网络，当时花了5~6天的时间。可以想象，没有GPU的加速，要完成如此大规模的数据集的多层神经网络训练要花费多长的时间。

随着深度网络层数的增加，训练集动辄以T为单位计算，现在深度学习的训练已经离不开GPU了，而GPU的计算能力也在不断的提升，以满足深度学习训练的计算需求。
